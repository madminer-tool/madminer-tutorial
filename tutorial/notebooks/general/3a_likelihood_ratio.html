

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>MadMiner physics tutorial (part 3A) &#8212; MadMiner Tutorial</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial/notebooks/general/3a_likelihood_ratio';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="MadMiner physics tutorial (part 3B)" href="3b_score.html" />
    <link rel="prev" title="Choose your adventure" href="../../6_metric_selection.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../0_intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../0_intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../1_video.html">Demo video</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../2_preliminaries.html">Preliminaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../3_overview.html">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="1_setup_process.html">Define process to study</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../4_morphing.html">Morphing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../morphing/basis_chooser.html">Morphing demo</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../5_data_generation.html">Create training data</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="2a_parton_analysis.html">Parton level</a></li>
<li class="toctree-l2"><a class="reference internal" href="2b_delphes_analysis.html">Delphes level</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../6_metric_selection.html">Train model</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Likelihood ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="3b_score.html">Score</a></li>
<li class="toctree-l2"><a class="reference internal" href="3c_likelihood.html">Likelihood</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../7_statistics.html">Statistical Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4a_limits.html">Limits on EFT parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="4b_fisher_information.html">Fisher Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="4c_information_geometry.html">Information Geometry</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../8_congratulations.html">Congratulations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../appendix/notebooks/A1_systematic_uncertainties.html">Systematic uncertainties</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix/notebooks/A2_ensemble_methods.html">Ensemble methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix/notebooks/A3_reweighting_samples.html">Reweighting existing samples</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deploy on REANA</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../reana/0_introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/1_demo_video.html">Demo video</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/2_workflow_setup.html">Setup workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/3_parametrization.html">Parametrization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/4_reana_setup.html">Setup REANA / MLFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/5_run_remotely.html">Run remotely</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reana/6_run_locally.html">Run locally</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/madminer-tool/madminer-tutorial/main?urlpath=tree/book/tutorial/notebooks/general/3a_likelihood_ratio.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/tutorial/notebooks/general/3a_likelihood_ratio.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>MadMiner physics tutorial (part 3A)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparations">Preparations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#make-unweighted-training-and-test-samples-with-augmented-data">1. Make (unweighted) training and test samples with augmented data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-cross-section-over-parameter-space">2. Plot cross section over parameter space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-likelihood-ratio-estimator">3. Train likelihood ratio estimator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-likelihood-ratio-estimator">4. Evaluate likelihood ratio estimator</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="madminer-physics-tutorial-part-3a">
<h1>MadMiner physics tutorial (part 3A)<a class="headerlink" href="#madminer-physics-tutorial-part-3a" title="Permalink to this heading">#</a></h1>
<p>Johann Brehmer, Felix Kling, Irina Espejo, and Kyle Cranmer 2018-2019</p>
<p>In part 3A of this tutorial we will finally train a neural network to estimate likelihood ratios. We assume that you have run part 1 and 2A of this tutorial. If, instead of 2A, you have run part 2B, you just have to load a different filename later.</p>
<section id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">from</span> <span class="nn">madminer.sampling</span> <span class="kn">import</span> <span class="n">SampleAugmenter</span>
<span class="kn">from</span> <span class="nn">madminer</span> <span class="kn">import</span> <span class="n">sampling</span>
<span class="kn">from</span> <span class="nn">madminer.ml</span> <span class="kn">import</span> <span class="n">ParameterizedRatioEstimator</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># MadMiner output</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)-5.5s</span><span class="s1"> </span><span class="si">%(name)-20.20s</span><span class="s1"> </span><span class="si">%(levelname)-7.7s</span><span class="s1"> </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="n">datefmt</span><span class="o">=</span><span class="s1">&#39;%H:%M&#39;</span><span class="p">,</span>
    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span>
<span class="p">)</span>

<span class="c1"># Output of all other modules (e.g. matplotlib)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">logging</span><span class="o">.</span><span class="n">Logger</span><span class="o">.</span><span class="n">manager</span><span class="o">.</span><span class="n">loggerDict</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;madminer&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="make-unweighted-training-and-test-samples-with-augmented-data">
<h2>1. Make (unweighted) training and test samples with augmented data<a class="headerlink" href="#make-unweighted-training-and-test-samples-with-augmented-data" title="Permalink to this heading">#</a></h2>
<p>At this point, we have all the information we need from the simulations. But the data is not quite ready to be used for machine learning. The <code class="docutils literal notranslate"><span class="pre">madminer.sampling</span></code> class <code class="docutils literal notranslate"><span class="pre">SampleAugmenter</span></code> will take care of the remaining book-keeping steps before we can train our estimators:</p>
<p>First, it unweights the samples, i.e. for a given parameter vector <code class="docutils literal notranslate"><span class="pre">theta</span></code> (or a distribution <code class="docutils literal notranslate"><span class="pre">p(theta)</span></code>) it picks events <code class="docutils literal notranslate"><span class="pre">x</span></code> such that their distribution follows <code class="docutils literal notranslate"><span class="pre">p(x|theta)</span></code>. The selected samples will all come from the event file we have so far, but their frequency is changed – some events will appear multiple times, some will disappear.</p>
<p>Second, <code class="docutils literal notranslate"><span class="pre">SampleAugmenter</span></code> calculates all the augmented data (“gold”) that is the key to our new inference methods. Depending on the specific technique, these are the joint likelihood ratio and / or the joint score. It saves all these pieces of information for the selected events in a set of numpy files that can easily be used in any machine learning framework.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SampleAugmenter</span><span class="p">(</span><span class="s1">&#39;data/lhe_data_shuffled.h5&#39;</span><span class="p">)</span>
<span class="c1"># sampler = SampleAugmenter(&#39;data/delphes_data_shuffled.h5&#39;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:34 madminer.analysis    INFO    Loading data from data/lhe_data_shuffled.h5
20:34 madminer.analysis    INFO    Found 2 parameters
20:34 madminer.analysis    INFO    Did not find nuisance parameters
20:34 madminer.analysis    INFO    Found 6 benchmarks, of which 6 physical
20:34 madminer.analysis    INFO    Found 3 observables
20:34 madminer.analysis    INFO    Found 89991 events
20:34 madminer.analysis    INFO      49991 signal events sampled from benchmark sm
20:34 madminer.analysis    INFO      10000 signal events sampled from benchmark w
20:34 madminer.analysis    INFO      10000 signal events sampled from benchmark neg_w
20:34 madminer.analysis    INFO      10000 signal events sampled from benchmark ww
20:34 madminer.analysis    INFO      10000 signal events sampled from benchmark neg_ww
20:34 madminer.analysis    INFO    Found morphing setup with 6 components
20:34 madminer.analysis    INFO    Did not find nuisance morphing setup
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">SampleAugmenter</span></code> class defines five different high-level functions to generate train or test samples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sample_train_plain()</span></code>, which only saves observations x, for instance for histograms or ABC;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_train_local()</span></code> for methods like SALLY and SALLINO, which will be demonstrated in the second part of the tutorial;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_train_density()</span></code> for neural density estimation techniques like MAF or SCANDAL;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_train_ratio()</span></code> for techniques like CARL, ROLR, CASCAL, and RASCAL, when only theta0 is parameterized;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_train_more_ratios()</span></code> for the same techniques, but with both theta0 and theta1 parameterized;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample_test()</span></code> for the evaluation of any method.</p></li>
</ul>
<p>For the arguments <code class="docutils literal notranslate"><span class="pre">theta</span></code>, <code class="docutils literal notranslate"><span class="pre">theta0</span></code>, or <code class="docutils literal notranslate"><span class="pre">theta1</span></code>, you can (and should!) use the helper functions <code class="docutils literal notranslate"><span class="pre">benchmark()</span></code>, <code class="docutils literal notranslate"><span class="pre">benchmarks()</span></code>, <code class="docutils literal notranslate"><span class="pre">morphing_point()</span></code>, <code class="docutils literal notranslate"><span class="pre">morphing_points()</span></code>, and <code class="docutils literal notranslate"><span class="pre">random_morphing_points()</span></code>, all defined in the <code class="docutils literal notranslate"><span class="pre">madminer.sampling</span></code> module.</p>
<p>Here we’ll train a likelihood ratio estimator with the ALICES method, so we focus on the <code class="docutils literal notranslate"><span class="pre">extract_samples_train_ratio()</span></code> function. We’ll sample the numerator hypothesis in the likelihood ratio with 1000 points drawn from a Gaussian prior, and fix the denominator hypothesis to the SM.</p>
<p>Note the keyword <code class="docutils literal notranslate"><span class="pre">sample_only_from_closest_benchmark=True</span></code>, which makes sure that for each parameter point we only use the events that were originally (in MG) generated from the closest benchmark. This reduces the statistical fluctuations in the outcome quite a bit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">r_xz</span><span class="p">,</span> <span class="n">t_xz</span><span class="p">,</span> <span class="n">n_effective</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_train_ratio</span><span class="p">(</span>
    <span class="n">theta0</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">random_morphing_points</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)]),</span>
    <span class="n">theta1</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="s1">&#39;sm&#39;</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span>
    <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;./data/samples&#39;</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;train_ratio&#39;</span><span class="p">,</span>
    <span class="n">sample_only_from_closest_benchmark</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_individual_n_effective</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:34 madminer.sampling    INFO    Extracting training sample for ratio-based methods. Numerator hypothesis: 1000 random morphing points, drawn from the following priors:
  theta_0 ~ Gaussian with mean 0.0 and std 0.5
  theta_1 ~ Gaussian with mean 0.0 and std 0.5, denominator hypothesis: sm
20:34 madminer.sampling    INFO    Starting sampling serially
20:34 madminer.sampling    WARNING Large statistical uncertainty on the total cross section when sampling from theta = [-0.35251218 -0.217245  ]: (0.001207 +/- 0.000370) pb (30.639815418386465 %). Skipping these warnings in the future...
20:34 madminer.sampling    INFO    Sampling from parameter point 50 / 1000
20:34 madminer.sampling    INFO    Sampling from parameter point 100 / 1000
20:34 madminer.sampling    INFO    Sampling from parameter point 150 / 1000
20:34 madminer.sampling    INFO    Sampling from parameter point 200 / 1000
20:34 madminer.sampling    INFO    Sampling from parameter point 250 / 1000
20:34 madminer.sampling    INFO    Sampling from parameter point 300 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 350 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 400 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 450 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 500 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 550 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 600 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 650 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 700 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 750 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 800 / 1000
20:35 madminer.sampling    INFO    Sampling from parameter point 850 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 900 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 950 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 1000 / 1000
20:36 madminer.sampling    INFO    Effective number of samples: mean 540.594777843479, with individual thetas ranging from 22.802180022668374 to 20938.588332878222
20:36 madminer.sampling    INFO    Starting sampling serially
20:36 madminer.sampling    INFO    Sampling from parameter point 50 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 100 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 150 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 200 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 250 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 300 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 350 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 400 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 450 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 500 / 1000
20:36 madminer.sampling    INFO    Sampling from parameter point 550 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 600 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 650 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 700 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 750 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 800 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 850 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 900 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 950 / 1000
20:37 madminer.sampling    INFO    Sampling from parameter point 1000 / 1000
20:37 madminer.sampling    INFO    Effective number of samples: mean 29966.000000000004, with individual thetas ranging from 29966.000000000004 to 29966.000000000004
</pre></div>
</div>
</div>
</div>
<p>For the evaluation we’ll need a test sample:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_test</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="s1">&#39;sm&#39;</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;./data/samples&#39;</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;test&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:37 madminer.sampling    INFO    Extracting evaluation sample. Sampling according to sm
20:37 madminer.sampling    INFO    Starting sampling serially
20:37 madminer.sampling    INFO    Sampling from parameter point 1 / 1
20:37 madminer.sampling    INFO    Effective number of samples: mean 10097.0, with individual thetas ranging from 10097.0 to 10097.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">neff</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_train_plain</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">morphing_point</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:37 madminer.sampling    INFO    Extracting plain training sample. Sampling according to [0.  0.5]
20:37 madminer.sampling    INFO    Starting sampling serially
20:37 madminer.sampling    INFO    Sampling from parameter point 1 / 1
20:37 madminer.sampling    INFO    Effective number of samples: mean 292.13068285197323, with individual thetas ranging from 292.13068285197323 to 292.13068285197323
</pre></div>
</div>
</div>
</div>
<p>You might notice the information about the “effective number of samples” in the output. This is defined as <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">max_events(weights)</span></code>; the smaller it is, the bigger the statistical fluctuations from too large weights. Let’s plot this over the parameter space:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">10000.</span>

<span class="n">cut</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">theta0</span><span class="p">[</span><span class="n">cut</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">theta0</span><span class="p">[</span><span class="n">cut</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">n_effective</span><span class="p">[</span><span class="n">cut</span><span class="p">],</span>
                 <span class="n">s</span><span class="o">=</span><span class="mf">30.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">),</span>
                 <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">cb</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;Effective number of samples&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/950b5b44070590018e67f506828b20e37cf5f28ae84e5b0ef5c3b880d4be5162.png" src="../../../_images/950b5b44070590018e67f506828b20e37cf5f28ae84e5b0ef5c3b880d4be5162.png" />
</div>
</div>
</section>
<section id="plot-cross-section-over-parameter-space">
<h2>2. Plot cross section over parameter space<a class="headerlink" href="#plot-cross-section-over-parameter-space" title="Permalink to this heading">#</a></h2>
<p>This is not strictly necessary, but we can also plot the cross section as a function of parameter space:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetas_benchmarks</span><span class="p">,</span> <span class="n">xsecs_benchmarks</span><span class="p">,</span> <span class="n">xsec_errors_benchmarks</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">cross_sections</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmarks</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">benchmarks</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="p">)</span>

<span class="n">thetas_morphing</span><span class="p">,</span> <span class="n">xsecs_morphing</span><span class="p">,</span> <span class="n">xsec_errors_morphing</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">cross_sections</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">random_morphing_points</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:37 madminer.sampling    INFO    Starting cross-section calculation
20:37 madminer.sampling    INFO    Starting cross-section calculation
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">2.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xsecs_morphing</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas_morphing</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">thetas_morphing</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">xsecs_morphing</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">40.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas_benchmarks</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">thetas_benchmarks</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">xsecs_benchmarks</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">200.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>

<span class="n">cb</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;xsec [pb]&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span><span class="mf">3.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span><span class="mf">3.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/562570898962d6e75a90f0714dbf6ea4428ac39d3c9832c4f57f5560fc734ade.png" src="../../../_images/562570898962d6e75a90f0714dbf6ea4428ac39d3c9832c4f57f5560fc734ade.png" />
</div>
</div>
<p>What  you see here is a morphing algorithm in action. We only asked MadGraph to calculate event weights (differential cross sections, or basically squared matrix elements) at six fixed parameter points (shown here as squares with black edges). But with our knowledge about the structure of the process we can interpolate any observable to any parameter point without loss (except that statistical uncertainties might increase)!</p>
</section>
<section id="train-likelihood-ratio-estimator">
<h2>3. Train likelihood ratio estimator<a class="headerlink" href="#train-likelihood-ratio-estimator" title="Permalink to this heading">#</a></h2>
<p>It’s now time to build the neural network that estimates the likelihood ratio. The central object for this is the <code class="docutils literal notranslate"><span class="pre">madminer.ml.ParameterizedRatioEstimator</span></code> class. It defines functions that train, save, load, and evaluate the estimators.</p>
<p>In the initialization, the keywords <code class="docutils literal notranslate"><span class="pre">n_hidden</span></code> and <code class="docutils literal notranslate"><span class="pre">activation</span></code> define the architecture of the (fully connected) neural network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">ParameterizedRatioEstimator</span><span class="p">(</span>
    <span class="n">n_hidden</span><span class="o">=</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span><span class="mi">60</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To train this model we will minimize the ALICES loss function described in <a class="reference external" href="https://arxiv.org/abs/1808.00973">“Likelihood-free inference with an improved cross-entropy estimator”</a>. Many alternatives, including RASCAL, are described in <a class="reference external" href="https://arxiv.org/abs/1805.00013">“Constraining Effective Field Theories With Machine Learning”</a> and <a class="reference external" href="https://arxiv.org/abs/1805.00020">“A Guide to Constraining Effective Field Theories With Machine Learning”</a>. There is also SCANDAL introduced in <a class="reference external" href="https://arxiv.org/abs/1805.12244">“Mining gold from implicit models to improve likelihood-free inference”</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;alices&#39;</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta0_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;data/samples/y_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">r_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/r_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">t_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/t_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scale_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">estimator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;models/alices&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:37 madminer.ml          INFO    Starting training
20:37 madminer.ml          INFO      Method:                 alices
20:37 madminer.ml          INFO      alpha:                  10
20:37 madminer.ml          INFO      Batch size:             128
20:37 madminer.ml          INFO      Optimizer:              amsgrad
20:37 madminer.ml          INFO      Epochs:                 10
20:37 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001
20:37 madminer.ml          INFO      Validation split:       0.25
20:37 madminer.ml          INFO      Early stopping:         True
20:37 madminer.ml          INFO      Scale inputs:           True
20:37 madminer.ml          INFO      Scale parameters:       True
20:37 madminer.ml          INFO      Shuffle labels          False
20:37 madminer.ml          INFO      Samples:                all
20:37 madminer.ml          INFO    Loading training data
20:37 madminer.utils.vario INFO      Loading data/samples/theta0_train_ratio.npy into RAM
20:37 madminer.utils.vario INFO      Loading data/samples/x_train_ratio.npy into RAM
20:37 madminer.utils.vario INFO      Loading data/samples/y_train_ratio.npy into RAM
20:37 madminer.utils.vario INFO      Loading data/samples/r_xz_train_ratio.npy into RAM
20:37 madminer.utils.vario INFO      Loading data/samples/t_xz_train_ratio.npy into RAM
20:37 madminer.ml          INFO    Found 500000 samples with 2 parameters and 3 observables
20:37 madminer.ml          INFO    Setting up input rescaling
20:37 madminer.ml          INFO    Rescaling parameters
20:37 madminer.ml          INFO    Setting up parameter rescaling
20:37 madminer.ml          INFO    Creating model
20:37 madminer.ml          INFO    Training model
20:37 madminer.utils.ml.tr INFO    Training on CPU with single precision
20:38 madminer.utils.ml.tr INFO      Epoch   1: train loss  1.03859 (improved_xe:  0.678, mse_score:  0.036)
20:38 madminer.utils.ml.tr INFO                 val. loss   0.96541 (improved_xe:  0.675, mse_score:  0.029)
20:39 madminer.utils.ml.tr INFO      Epoch   2: train loss  0.96694 (improved_xe:  0.675, mse_score:  0.029)
20:39 madminer.utils.ml.tr INFO                 val. loss   0.94460 (improved_xe:  0.675, mse_score:  0.027)
20:40 madminer.utils.ml.tr INFO      Epoch   3: train loss  0.95053 (improved_xe:  0.675, mse_score:  0.028)
20:40 madminer.utils.ml.tr INFO                 val. loss   0.93165 (improved_xe:  0.674, mse_score:  0.026)
20:41 madminer.utils.ml.tr INFO      Epoch   4: train loss  0.94048 (improved_xe:  0.675, mse_score:  0.027)
20:41 madminer.utils.ml.tr INFO                 val. loss   0.93224 (improved_xe:  0.675, mse_score:  0.026)
20:41 madminer.utils.ml.tr INFO      Epoch   5: train loss  0.93394 (improved_xe:  0.675, mse_score:  0.026)
20:41 madminer.utils.ml.tr INFO                 val. loss   0.92634 (improved_xe:  0.674, mse_score:  0.025)
20:42 madminer.utils.ml.tr INFO      Epoch   6: train loss  0.93002 (improved_xe:  0.674, mse_score:  0.026)
20:42 madminer.utils.ml.tr INFO                 val. loss   0.91939 (improved_xe:  0.674, mse_score:  0.025)
20:43 madminer.utils.ml.tr INFO      Epoch   7: train loss  0.92634 (improved_xe:  0.674, mse_score:  0.025)
20:43 madminer.utils.ml.tr INFO                 val. loss   0.91647 (improved_xe:  0.674, mse_score:  0.024)
20:44 madminer.utils.ml.tr INFO      Epoch   8: train loss  0.92436 (improved_xe:  0.674, mse_score:  0.025)
20:44 madminer.utils.ml.tr INFO                 val. loss   0.91579 (improved_xe:  0.674, mse_score:  0.024)
20:44 madminer.utils.ml.tr INFO      Epoch   9: train loss  0.92230 (improved_xe:  0.674, mse_score:  0.025)
20:44 madminer.utils.ml.tr INFO                 val. loss   0.91520 (improved_xe:  0.674, mse_score:  0.024)
20:45 madminer.utils.ml.tr INFO      Epoch  10: train loss  0.92073 (improved_xe:  0.674, mse_score:  0.025)
20:45 madminer.utils.ml.tr INFO                 val. loss   0.91580 (improved_xe:  0.674, mse_score:  0.024)
20:45 madminer.utils.ml.tr INFO    Early stopping after epoch 9, with loss  0.91520 compared to final loss  0.91580
20:45 madminer.utils.ml.tr INFO    Training time spend on:
20:45 madminer.utils.ml.tr INFO                      initialize model:   0.00h
20:45 madminer.utils.ml.tr INFO                                   ALL:   0.13h
20:45 madminer.utils.ml.tr INFO                            check data:   0.00h
20:45 madminer.utils.ml.tr INFO                          make dataset:   0.00h
20:45 madminer.utils.ml.tr INFO                       make dataloader:   0.00h
20:45 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h
20:45 madminer.utils.ml.tr INFO                   initialize training:   0.00h
20:45 madminer.utils.ml.tr INFO                                set lr:   0.00h
20:45 madminer.utils.ml.tr INFO                   load training batch:   0.03h
20:45 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h
20:45 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.01h
20:45 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.03h
20:45 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.01h
20:45 madminer.utils.ml.tr INFO                 training forward pass:   0.04h
20:45 madminer.utils.ml.tr INFO                   training sum losses:   0.00h
20:45 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h
20:45 madminer.utils.ml.tr INFO                         opt: backward:   0.02h
20:45 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h
20:45 madminer.utils.ml.tr INFO                             opt: step:   0.00h
20:45 madminer.utils.ml.tr INFO                        optimizer step:   0.03h
20:45 madminer.utils.ml.tr INFO                 load validation batch:   0.01h
20:45 madminer.utils.ml.tr INFO               validation forward pass:   0.01h
20:45 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h
20:45 madminer.utils.ml.tr INFO                        early stopping:   0.00h
20:45 madminer.utils.ml.tr INFO                          report epoch:   0.00h
20:45 madminer.ml          INFO    Saving model to models/alices
</pre></div>
</div>
</div>
</div>
<p>Let’s for fun also train a model that only used <code class="docutils literal notranslate"><span class="pre">pt_j1</span></code> as input observable, which can be specified using the option <code class="docutils literal notranslate"><span class="pre">features</span></code> when defining the <code class="docutils literal notranslate"><span class="pre">ParameterizedRatioEstimator</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator_pt</span> <span class="o">=</span> <span class="n">ParameterizedRatioEstimator</span><span class="p">(</span>
    <span class="n">n_hidden</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span><span class="mi">40</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
    <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">estimator_pt</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;alices&#39;</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta0_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;data/samples/y_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">r_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/r_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">t_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/t_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scale_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">estimator_pt</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;models/alices_pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:45 madminer.ml          INFO    Starting training
20:45 madminer.ml          INFO      Method:                 alices
20:45 madminer.ml          INFO      alpha:                  8
20:45 madminer.ml          INFO      Batch size:             128
20:45 madminer.ml          INFO      Optimizer:              amsgrad
20:45 madminer.ml          INFO      Epochs:                 10
20:45 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001
20:45 madminer.ml          INFO      Validation split:       0.25
20:45 madminer.ml          INFO      Early stopping:         True
20:45 madminer.ml          INFO      Scale inputs:           True
20:45 madminer.ml          INFO      Scale parameters:       True
20:45 madminer.ml          INFO      Shuffle labels          False
20:45 madminer.ml          INFO      Samples:                all
20:45 madminer.ml          INFO    Loading training data
20:45 madminer.utils.vario INFO      Loading data/samples/theta0_train_ratio.npy into RAM
20:45 madminer.utils.vario INFO      Loading data/samples/x_train_ratio.npy into RAM
20:45 madminer.utils.vario INFO      Loading data/samples/y_train_ratio.npy into RAM
20:45 madminer.utils.vario INFO      Loading data/samples/r_xz_train_ratio.npy into RAM
20:45 madminer.utils.vario INFO      Loading data/samples/t_xz_train_ratio.npy into RAM
20:45 madminer.ml          INFO    Found 500000 samples with 2 parameters and 3 observables
20:45 madminer.ml          INFO    Setting up input rescaling
20:45 madminer.ml          INFO    Rescaling parameters
20:45 madminer.ml          INFO    Setting up parameter rescaling
20:45 madminer.ml          INFO    Only using 1 of 3 observables
20:45 madminer.ml          INFO    Creating model
20:45 madminer.ml          INFO    Training model
20:45 madminer.utils.ml.tr INFO    Training on CPU with single precision
20:46 madminer.utils.ml.tr INFO      Epoch   1: train loss  1.08569 (improved_xe:  0.684, mse_score:  0.050)
20:46 madminer.utils.ml.tr INFO                 val. loss   1.06532 (improved_xe:  0.682, mse_score:  0.048)
20:46 madminer.utils.ml.tr INFO      Epoch   2: train loss  1.05357 (improved_xe:  0.682, mse_score:  0.046)
20:46 madminer.utils.ml.tr INFO                 val. loss   1.06289 (improved_xe:  0.682, mse_score:  0.048)
20:47 madminer.utils.ml.tr INFO      Epoch   3: train loss  1.05015 (improved_xe:  0.682, mse_score:  0.046)
20:47 madminer.utils.ml.tr INFO                 val. loss   1.06356 (improved_xe:  0.682, mse_score:  0.048)
20:48 madminer.utils.ml.tr INFO      Epoch   4: train loss  1.04808 (improved_xe:  0.682, mse_score:  0.046)
20:48 madminer.utils.ml.tr INFO                 val. loss   1.05583 (improved_xe:  0.682, mse_score:  0.047)
20:49 madminer.utils.ml.tr INFO      Epoch   5: train loss  1.04594 (improved_xe:  0.682, mse_score:  0.046)
20:49 madminer.utils.ml.tr INFO                 val. loss   1.05662 (improved_xe:  0.682, mse_score:  0.047)
20:49 madminer.utils.ml.tr INFO      Epoch   6: train loss  1.04515 (improved_xe:  0.682, mse_score:  0.045)
20:49 madminer.utils.ml.tr INFO                 val. loss   1.05398 (improved_xe:  0.682, mse_score:  0.047)
20:50 madminer.utils.ml.tr INFO      Epoch   7: train loss  1.04437 (improved_xe:  0.682, mse_score:  0.045)
20:50 madminer.utils.ml.tr INFO                 val. loss   1.05249 (improved_xe:  0.682, mse_score:  0.046)
20:51 madminer.utils.ml.tr INFO      Epoch   8: train loss  1.04362 (improved_xe:  0.682, mse_score:  0.045)
20:51 madminer.utils.ml.tr INFO                 val. loss   1.05231 (improved_xe:  0.682, mse_score:  0.046)
20:52 madminer.utils.ml.tr INFO      Epoch   9: train loss  1.04301 (improved_xe:  0.682, mse_score:  0.045)
20:52 madminer.utils.ml.tr INFO                 val. loss   1.05363 (improved_xe:  0.682, mse_score:  0.046)
20:52 madminer.utils.ml.tr INFO      Epoch  10: train loss  1.04283 (improved_xe:  0.682, mse_score:  0.045)
20:52 madminer.utils.ml.tr INFO                 val. loss   1.05177 (improved_xe:  0.682, mse_score:  0.046)
20:52 madminer.utils.ml.tr INFO    Early stopping did not improve performance
20:52 madminer.utils.ml.tr INFO    Training time spend on:
20:52 madminer.utils.ml.tr INFO                      initialize model:   0.00h
20:52 madminer.utils.ml.tr INFO                                   ALL:   0.12h
20:52 madminer.utils.ml.tr INFO                            check data:   0.00h
20:52 madminer.utils.ml.tr INFO                          make dataset:   0.00h
20:52 madminer.utils.ml.tr INFO                       make dataloader:   0.00h
20:52 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h
20:52 madminer.utils.ml.tr INFO                   initialize training:   0.00h
20:52 madminer.utils.ml.tr INFO                                set lr:   0.00h
20:52 madminer.utils.ml.tr INFO                   load training batch:   0.03h
20:52 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h
20:52 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.01h
20:52 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.03h
20:52 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.01h
20:52 madminer.utils.ml.tr INFO                 training forward pass:   0.04h
20:52 madminer.utils.ml.tr INFO                   training sum losses:   0.00h
20:52 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h
20:52 madminer.utils.ml.tr INFO                         opt: backward:   0.02h
20:52 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h
20:52 madminer.utils.ml.tr INFO                             opt: step:   0.00h
20:52 madminer.utils.ml.tr INFO                        optimizer step:   0.03h
20:52 madminer.utils.ml.tr INFO                 load validation batch:   0.01h
20:52 madminer.utils.ml.tr INFO               validation forward pass:   0.01h
20:52 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h
20:52 madminer.utils.ml.tr INFO                        early stopping:   0.00h
20:52 madminer.utils.ml.tr INFO                          report epoch:   0.00h
20:52 madminer.ml          INFO    Saving model to models/alices_pt
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluate-likelihood-ratio-estimator">
<h2>4. Evaluate likelihood ratio estimator<a class="headerlink" href="#evaluate-likelihood-ratio-estimator" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">estimator.evaluate_log_likelihood_ratio(theta,x)</span></code> estimated the log likelihood ratio and the score for all combination between the given phase-space points <code class="docutils literal notranslate"><span class="pre">x</span></code> and parameters <code class="docutils literal notranslate"><span class="pre">theta</span></code>. That is, if given 100 events <code class="docutils literal notranslate"><span class="pre">x</span></code> and a grid of 25 <code class="docutils literal notranslate"><span class="pre">theta</span></code> points, it will return 25*100 estimates for the log likelihood ratio and 25*100 estimates for the score, both indexed by <code class="docutils literal notranslate"><span class="pre">[i_theta,i_x]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta_each</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>
<span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">theta_each</span><span class="p">,</span> <span class="n">theta_each</span><span class="p">)</span>
<span class="n">theta_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">theta0</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">theta1</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span><span class="o">.</span><span class="n">T</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/samples/theta_grid.npy&#39;</span><span class="p">,</span> <span class="n">theta_grid</span><span class="p">)</span>

<span class="n">theta_denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]])</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/samples/theta_ref.npy&#39;</span><span class="p">,</span> <span class="n">theta_denom</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;models/alices&#39;</span><span class="p">)</span>

<span class="n">log_r_hat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">evaluate_log_likelihood_ratio</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta_grid.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_test.npy&#39;</span><span class="p">,</span>
    <span class="n">evaluate_score</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20:52 madminer.ml          INFO    Loading model from models/alices
20:52 madminer.ml          INFO    Loading evaluation data
20:52 madminer.utils.vario INFO      Loading data/samples/x_test.npy into RAM
20:52 madminer.utils.vario INFO      Loading data/samples/theta_grid.npy into RAM
20:52 madminer.ml          INFO    Starting ratio evaluation for 625000 x-theta combinations
20:52 madminer.ml          INFO    Evaluation done
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the result:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bin_size</span> <span class="o">=</span> <span class="n">theta_each</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">theta_each</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">theta_each</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">bin_size</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">theta_each</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">bin_size</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_each</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">expected_llr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_r_hat</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">best_fit</span> <span class="o">=</span> <span class="n">theta_grid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="o">-</span><span class="mf">2.</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">)]</span>

<span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">)</span>
    
<span class="n">pcm</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">expected_llr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">)),</span>
                    <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">),</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis_r&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pcm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">extend</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">best_fit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">best_fit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mf">80.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta_0$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta_1$&#39;</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbb</span><span class="si">{E}</span><span class="s1">_x [ -2\, \log \,\hat</span><span class="si">{r}</span><span class="s1">(x | \theta, \theta_</span><span class="si">{SM}</span><span class="s1">) ]$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/82bfa5792bce7c417e50c09fbb9cb3774c9e00c0b2807b5db7f976fe122d585b.png" src="../../../_images/82bfa5792bce7c417e50c09fbb9cb3774c9e00c0b2807b5db7f976fe122d585b.png" />
</div>
</div>
<p>Note that in this tutorial our sample size was very small, and the network might not really have a chance to converge to the correct likelihood ratio function. So don’t worry if you find a minimum that is not at the right point (the SM, i.e. the origin in this plot). Feel free to dial up the event numbers in the run card as well as the training samples and see what happens then!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorial/notebooks/general"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../../6_metric_selection.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Choose your adventure</p>
      </div>
    </a>
    <a class="right-next"
       href="3b_score.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MadMiner physics tutorial (part 3B)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparations">Preparations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#make-unweighted-training-and-test-samples-with-augmented-data">1. Make (unweighted) training and test samples with augmented data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-cross-section-over-parameter-space">2. Plot cross section over parameter space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-likelihood-ratio-estimator">3. Train likelihood ratio estimator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-likelihood-ratio-estimator">4. Evaluate likelihood ratio estimator</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By MadMiner team
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  This page was created by the <a href="https://github.com/madminer-tool/madminer">MadMiner Team</a>.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>