<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Likelihood Ratio</title>
  <meta name="description" content="        Likelihood Ratio    MadMiner particle physics tutorial Part 3a: Training a likelihood ratio estimator Johann Brehmer, Felix Kling, Irina Espejo, and ...">

  <link rel="canonical" href="https://cranmer.github.io/madminer-tutorial/tutorial_particle_physics/3a_likelihood_ratio.html">
  <link rel="alternate" type="application/rss+xml" title="MadMiner Tutorial" href="https://cranmer.github.io/madminer-tutorial/feed.xml">

  <meta property="og:url"         content="https://cranmer.github.io/madminer-tutorial/tutorial_particle_physics/3a_likelihood_ratio.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Likelihood Ratio" />
<meta property="og:description" content="        Likelihood Ratio    MadMiner particle physics tutorial Part 3a: Training a likelihood ratio estimator Johann Brehmer, Felix Kling, Irina Espejo, and ..." />
<meta property="og:image"       content="https://iris-hep.org/assets/logos/madminer-square.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://cranmer.github.io/madminer-tutorial/tutorial_particle_physics/3a_likelihood_ratio.html",
  "headline": "Likelihood Ratio",
  "datePublished": "2020-02-27T15:40:19-05:00",
  "dateModified": "2020-02-27T15:40:19-05:00",
  "description": "        Likelihood Ratio    MadMiner particle physics tutorial Part 3a: Training a likelihood ratio estimator Johann Brehmer, Felix Kling, Irina Espejo, and ...",
  "author": {
    "@type": "Person",
    "name": "Kyle Cranmer,"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cranmer.github.io/madminer-tutorial",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://cranmer.github.io/madminer-tutorial",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/madminer-tutorial/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/madminer-tutorial/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/madminer-tutorial/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/madminer-tutorial/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/madminer-tutorial';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/madminer-tutorial/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


<!-- Display Thebelab button in each code cell -->
<script>
/**
 * Set up thebelab button for code blocks
 */

const thebelabCellButton = id =>
  `<a id="thebelab-cell-button-${id}" class="btn thebebtn o-tooltip--left" data-tooltip="Interactive Mode">
    <img src="/madminer-tutorial/assets/images/edit-button.svg" alt="Start thebelab interactive mode">
  </a>`


const addThebelabButtonToCodeCells =  () => {

  const codeCells = document.querySelectorAll('div.input_area > div.highlight:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("thebelab-cell-button-" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', thebelabCellButton(id));
    }
  })
}

initFunction(addThebelabButtonToCodeCells);
</script>


<script src="https://unpkg.com/thebelab@latest/lib/index.js" async></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)

                // Clean up the language to make it work w/ CodeMirror and add it to the cell
                dataLanguage = ""
                dataLanguage = detectLanguage(dataLanguage);
                codeCell.setAttribute('data-language', dataLanguage)
                codeCell.setAttribute('data-executable', 'true')

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyAndThebeButtons = document.querySelectorAll('.copybtn, .thebebtn')
            copyAndThebeButtons.forEach((button, index) => {
                button.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });

            // Find any cells with an initialization tag and ask ThebeLab to run them when ready
            var thebeInitCells = document.querySelectorAll('div.tag_thebelab-init');
            thebeInitCells.forEach((cell) => {
                console.log("Initializing ThebeLab with cell: " + cell.id);
                cell.querySelector('.thebelab-run-button').click();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButtons = document.querySelectorAll('[id^=thebelab], [id$=thebelab]')
        thebelabButtons.forEach((thebelabButton,index) => {
            if (thebelabButton === null) {
                setTimeout(initThebelab, 250)
                return
            };
            thebelabButton.addEventListener('click', addThebelabToCodeCells);
        });
    }

    // Initialize Thebelab
    initFunction(initThebelab);

// Helper function to munge the language name
var detectLanguage = (language) => {
    if (language.indexOf('python') > -1) {
        language = "python";
    }
    return language;
}
</script>



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/madminer-tutorial/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>



  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/madminer-tutorial/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/madminer-tutorial/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/madminer-tutorial/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/madminer-tutorial/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/madminer-tutorial/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/madminer-tutorial/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "Made with Jupyter Book"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "YOUR-ORG/YOUR-REPO",
    ref: "gh-pages",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python2",
    path: "content/tutorial_particle_physics"
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="/madminer-tutorial/"><img src="https://iris-hep.org/assets/logos/madminer-square.png" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">MadMiner Tutorial</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/intro.html"
        >
          
          Introduction
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">MadMiner Tutorial</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/preliminaries">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/preliminaries.html"
        >
          
          Preliminaries
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/tutorial_particle_physics/1_setup">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/tutorial_particle_physics/1_setup.html"
        >
          
          Define process to study
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parton_or_delphes">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/parton_or_delphes.html"
        >
          
          Create training data
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/set_mg_dir">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/set_mg_dir.html"
              >
                
                Set MadGraph Directory
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/2a_parton_level_analysis">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/2a_parton_level_analysis.html"
              >
                
                Parton Level
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/2b_delphes_level_analysis">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/2b_delphes_level_analysis.html"
              >
                
                With Delphes
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/choose_surrogate">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/choose_surrogate.html"
        >
          
          Train model
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/3a_likelihood_ratio">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/3a_likelihood_ratio.html"
              >
                
                Likelihood Ratio
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/3b_score">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/3b_score.html"
              >
                
                Score
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/3c_likelihood">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/3c_likelihood.html"
              >
                
                Likelihood
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/statistics">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/statistics.html"
        >
          
          Statistical Analysis
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/4a_limits">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/4a_limits.html"
              >
                
                Limits on EFT parameters
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/4b_fisher_information">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/4b_fisher_information.html"
              >
                
                Fisher Information
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/4c_information_geometry">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/4c_information_geometry.html"
              >
                
                Information Geometry
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/tutorial_particle_physics/A1_systematic_uncertainties">
        <a class="c-sidebar__entry"
          href="/madminer-tutorial/tutorial_particle_physics/A1_systematic_uncertainties.html"
        >
          
          Appendix
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/A1_systematic_uncertainties">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/A1_systematic_uncertainties.html"
              >
                
                Appendix
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/A2_ensemble_methods">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/A2_ensemble_methods.html"
              >
                
                Ensemble methods
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/tutorial_particle_physics/A3_reweighting_existing_samples">
              <a class="c-sidebar__entry"
                href="/madminer-tutorial/tutorial_particle_physics/A3_reweighting_existing_samples.html"
              >
                
                Reweighting existing samples
              </a>
            </li>
            
            
          
        </ul>
      

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/madminer-tutorial/assets/images/download-solid.svg" alt="Download" /></button>
    <div class="download-buttons">
        <a href="/madminer-tutorial/content/tutorial_particle_physics/3a_likelihood_ratio.ipynb" download>
        <button id="interact-button-download" class="interact-button">.ipynb</button>
        </a>
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


  <button id="interact-button-thebelab" class="interact-button">Thebelab</button>

  
  
  


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><img src="/madminer-tutorial/assets/images/list-solid.svg" alt="Search" />   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/madminer-tutorial/search.html" class="topbar-right-button" id="search-button">
    <img src="/madminer-tutorial/assets/images/search-solid.svg" alt="Search" />
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
                  <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Likelihood Ratio</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="MadMiner-particle-physics-tutorial">MadMiner particle physics tutorial<a class="anchor-link" href="#MadMiner-particle-physics-tutorial"> </a></h1><h1 id="Part-3a:-Training-a-likelihood-ratio-estimator">Part 3a: Training a likelihood ratio estimator<a class="anchor-link" href="#Part-3a:-Training-a-likelihood-ratio-estimator"> </a></h1><p>Johann Brehmer, Felix Kling, Irina Espejo, and Kyle Cranmer 2018-2019</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In part 3a of this tutorial we will finally train a neural network to estimate likelihood ratios. We assume that you have run part 1 and 2a of this tutorial. If, instead of 2a, you have run part 2b, you just have to load a different filename later.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparations">Preparations<a class="anchor-link" href="#Preparations"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">from</span> <span class="nn">madminer.sampling</span> <span class="kn">import</span> <span class="n">SampleAugmenter</span>
<span class="kn">from</span> <span class="nn">madminer</span> <span class="kn">import</span> <span class="n">sampling</span>
<span class="kn">from</span> <span class="nn">madminer.ml</span> <span class="kn">import</span> <span class="n">ParameterizedRatioEstimator</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># MadMiner output</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="n">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)-5.5s</span><span class="s1"> </span><span class="si">%(name)-20.20s</span><span class="s1"> </span><span class="si">%(levelname)-7.7s</span><span class="s1"> </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="n">datefmt</span><span class="o">=</span><span class="s1">&#39;%H:%M&#39;</span><span class="p">,</span>
    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span>
<span class="p">)</span>

<span class="c1"># Output of all other modules (e.g. matplotlib)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">logging</span><span class="o">.</span><span class="n">Logger</span><span class="o">.</span><span class="n">manager</span><span class="o">.</span><span class="n">loggerDict</span><span class="p">:</span>
    <span class="k">if</span> <span class="s2">&quot;madminer&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Make-(unweighted)-training-and-test-samples-with-augmented-data">1. Make (unweighted) training and test samples with augmented data<a class="anchor-link" href="#1.-Make-(unweighted)-training-and-test-samples-with-augmented-data"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point, we have all the information we need from the simulations. But the data is not quite ready to be used for machine learning. The <code>madminer.sampling</code> class <code>SampleAugmenter</code> will take care of the remaining book-keeping steps before we can train our estimators:</p>
<p>First, it unweights the samples, i.e. for a given parameter vector <code>theta</code> (or a distribution <code>p(theta)</code>) it picks events <code>x</code> such that their distribution follows <code>p(x|theta)</code>. The selected samples will all come from the event file we have so far, but their frequency is changed -- some events will appear multiple times, some will disappear.</p>
<p>Second, <code>SampleAugmenter</code> calculates all the augmented data ("gold") that is the key to our new inference methods. Depending on the specific technique, these are the joint likelihood ratio and / or the joint score. It saves all these pieces of information for the selected events in a set of numpy files that can easily be used in any machine learning framework.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">SampleAugmenter</span><span class="p">(</span><span class="s1">&#39;data/lhe_data_shuffled.h5&#39;</span><span class="p">)</span>
<span class="c1"># sampler = SampleAugmenter(&#39;data/delphes_data_shuffled.h5&#39;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>20:00 madminer.analysis    INFO    Loading data from data/lhe_data_shuffled.h5
20:00 madminer.analysis    INFO    Found 2 parameters
20:00 madminer.analysis    INFO    Did not find nuisance parameters
20:00 madminer.analysis    INFO    Found 6 benchmarks, of which 6 physical
20:00 madminer.analysis    INFO    Found 3 observables
20:00 madminer.analysis    INFO    Found 539913 events
20:00 madminer.analysis    INFO      499913 signal events sampled from benchmark sm
20:00 madminer.analysis    INFO      10000 signal events sampled from benchmark w
20:00 madminer.analysis    INFO      10000 signal events sampled from benchmark neg_w
20:00 madminer.analysis    INFO      10000 signal events sampled from benchmark ww
20:00 madminer.analysis    INFO      10000 signal events sampled from benchmark neg_ww
20:00 madminer.analysis    INFO    Found morphing setup with 6 components
20:00 madminer.analysis    INFO    Did not find nuisance morphing setup
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>SampleAugmenter</code> class defines five different high-level functions to generate train or test samples:</p>
<ul>
<li><code>sample_train_plain()</code>, which only saves observations x, for instance for histograms or ABC;</li>
<li><code>sample_train_local()</code> for methods like SALLY and SALLINO, which will be demonstrated in the second part of the tutorial;</li>
<li><code>sample_train_density()</code> for neural density estimation techniques like MAF or SCANDAL;</li>
<li><code>sample_train_ratio()</code> for techniques like CARL, ROLR, CASCAL, and RASCAL, when only theta0 is parameterized;</li>
<li><code>sample_train_more_ratios()</code> for the same techniques, but with both theta0 and theta1 parameterized;</li>
<li><code>sample_test()</code> for the evaluation of any method.</li>
</ul>
<p>For the arguments <code>theta</code>, <code>theta0</code>, or <code>theta1</code>, you can (and should!) use the helper functions <code>benchmark()</code>, <code>benchmarks()</code>, <code>morphing_point()</code>, <code>morphing_points()</code>, and <code>random_morphing_points()</code>, all defined in the <code>madminer.sampling</code> module.</p>
<p>Here we'll train a likelihood ratio estimator with the ALICES method, so we focus on the <code>extract_samples_train_ratio()</code> function. We'll sample the numerator hypothesis in the likelihood ratio with 1000 points drawn from a Gaussian prior, and fix the denominator hypothesis to the SM.</p>
<p>Note the keyword <code>sample_only_from_closest_benchmark=True</code>, which makes sure that for each parameter point we only use the events that were originally (in MG) generated from the closest benchmark. This reduces the statistical fluctuations in the outcome quite a bit.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">r_xz</span><span class="p">,</span> <span class="n">t_xz</span><span class="p">,</span> <span class="n">n_effective</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_train_ratio</span><span class="p">(</span>
    <span class="n">theta0</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">random_morphing_points</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)]),</span>
    <span class="n">theta1</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="s1">&#39;sm&#39;</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span>
    <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;./data/samples&#39;</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;train_ratio&#39;</span><span class="p">,</span>
    <span class="n">sample_only_from_closest_benchmark</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">return_individual_n_effective</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>20:00 madminer.sampling    INFO    Extracting training sample for ratio-based methods. Numerator hypothesis: 10000 random morphing points, drawn from the following priors:
  theta_0 ~ Gaussian with mean 0.0 and std 0.5
  theta_1 ~ Gaussian with mean 0.0 and std 0.5, denominator hypothesis: sm
20:00 madminer.sampling    INFO    Starting sampling serially
20:00 madminer.sampling    WARNING Large statistical uncertainty on the total cross section when sampling from theta = [1.5917442 0.8098811]: (0.001066 +/- 0.000134) pb (12.538420533785002 %). Skipping these warnings in the future...
20:01 madminer.sampling    WARNING For this value of theta, 1 / 92682 events have negative weight and will be ignored
20:01 madminer.sampling    WARNING For this value of theta, 1 / 92682 events have negative weight and will be ignored
20:02 madminer.sampling    INFO    Sampling from parameter point 500 / 10000
20:03 madminer.sampling    WARNING For this value of theta, 1 / 92646 events have negative weight and will be ignored
20:03 madminer.sampling    WARNING Skipping warnings about negative weights in the future...
20:03 madminer.sampling    INFO    Sampling from parameter point 1000 / 10000
20:05 madminer.sampling    INFO    Sampling from parameter point 1500 / 10000
20:06 madminer.sampling    INFO    Sampling from parameter point 2000 / 10000
20:08 madminer.sampling    INFO    Sampling from parameter point 2500 / 10000
20:09 madminer.sampling    INFO    Sampling from parameter point 3000 / 10000
20:11 madminer.sampling    INFO    Sampling from parameter point 3500 / 10000
20:12 madminer.sampling    INFO    Sampling from parameter point 4000 / 10000
20:13 madminer.sampling    INFO    Sampling from parameter point 4500 / 10000
20:15 madminer.sampling    INFO    Sampling from parameter point 5000 / 10000
20:16 madminer.sampling    INFO    Sampling from parameter point 5500 / 10000
20:18 madminer.sampling    INFO    Sampling from parameter point 6000 / 10000
20:19 madminer.sampling    INFO    Sampling from parameter point 6500 / 10000
20:20 madminer.sampling    INFO    Sampling from parameter point 7000 / 10000
20:22 madminer.sampling    INFO    Sampling from parameter point 7500 / 10000
20:23 madminer.sampling    INFO    Sampling from parameter point 8000 / 10000
20:25 madminer.sampling    INFO    Sampling from parameter point 8500 / 10000
20:27 madminer.sampling    INFO    Sampling from parameter point 9000 / 10000
20:29 madminer.sampling    INFO    Sampling from parameter point 9500 / 10000
20:31 madminer.sampling    INFO    Sampling from parameter point 10000 / 10000
20:31 madminer.sampling    INFO    Effective number of samples: mean 6091.587539151862, with individual thetas ranging from 146.7231157941054 to 273881.9916048277
20:31 madminer.sampling    INFO    Starting sampling serially
20:33 madminer.sampling    INFO    Sampling from parameter point 500 / 10000
20:35 madminer.sampling    INFO    Sampling from parameter point 1000 / 10000
20:36 madminer.sampling    INFO    Sampling from parameter point 1500 / 10000
20:38 madminer.sampling    INFO    Sampling from parameter point 2000 / 10000
20:39 madminer.sampling    INFO    Sampling from parameter point 2500 / 10000
20:41 madminer.sampling    INFO    Sampling from parameter point 3000 / 10000
20:42 madminer.sampling    INFO    Sampling from parameter point 3500 / 10000
20:43 madminer.sampling    INFO    Sampling from parameter point 4000 / 10000
20:45 madminer.sampling    INFO    Sampling from parameter point 4500 / 10000
20:46 madminer.sampling    INFO    Sampling from parameter point 5000 / 10000
20:48 madminer.sampling    INFO    Sampling from parameter point 5500 / 10000
20:50 madminer.sampling    INFO    Sampling from parameter point 6000 / 10000
20:51 madminer.sampling    INFO    Sampling from parameter point 6500 / 10000
20:53 madminer.sampling    INFO    Sampling from parameter point 7000 / 10000
20:54 madminer.sampling    INFO    Sampling from parameter point 7500 / 10000
20:56 madminer.sampling    INFO    Sampling from parameter point 8000 / 10000
20:57 madminer.sampling    INFO    Sampling from parameter point 8500 / 10000
20:59 madminer.sampling    INFO    Sampling from parameter point 9000 / 10000
21:00 madminer.sampling    INFO    Sampling from parameter point 9500 / 10000
21:02 madminer.sampling    INFO    Sampling from parameter point 10000 / 10000
21:02 madminer.sampling    INFO    Effective number of samples: mean 300067.99999999994, with individual thetas ranging from 300067.9999999998 to 300067.9999999998
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the evaluation we'll need a test sample:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_test</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="s1">&#39;sm&#39;</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;./data/samples&#39;</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;test&#39;</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>21:02 madminer.sampling    INFO    Extracting evaluation sample. Sampling according to sm
21:02 madminer.sampling    INFO    Starting sampling serially
21:02 madminer.sampling    INFO    Sampling from parameter point 1 / 1
21:02 madminer.sampling    INFO    Effective number of samples: mean 99945.99999999999, with individual thetas ranging from 99945.99999999996 to 99945.99999999996
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">neff</span><span class="o">=</span><span class="n">sampler</span><span class="o">.</span><span class="n">sample_train_plain</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">morphing_point</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>21:02 madminer.sampling    INFO    Extracting plain training sample. Sampling according to [0.  0.5]
21:02 madminer.sampling    INFO    Starting sampling serially
21:02 madminer.sampling    INFO    Sampling from parameter point 1 / 1
21:02 madminer.sampling    INFO    Effective number of samples: mean 2751.5649261011226, with individual thetas ranging from 2751.5649261011235 to 2751.5649261011235
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You might notice the information about the "eeffective number of samples" in the output. This is defined as <code>1 / max_events(weights)</code>; the smaller it is, the bigger the statistical fluctuations from too large weights. Let's plot this over the parameter space:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">10000.</span>

<span class="n">cut</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">theta0</span><span class="p">[</span><span class="n">cut</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">theta0</span><span class="p">[</span><span class="n">cut</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">n_effective</span><span class="p">[</span><span class="n">cut</span><span class="p">],</span>
                 <span class="n">s</span><span class="o">=</span><span class="mf">30.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">),</span>
                 <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">cb</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;Effective number of samples&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/tutorial_particle_physics/3a_likelihood_ratio_14_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Plot-cross-section-over-parameter-space">2. Plot cross section over parameter space<a class="anchor-link" href="#2.-Plot-cross-section-over-parameter-space"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is not strictly necessary, but we can also plot the cross section as a function of parameter space:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">thetas_benchmarks</span><span class="p">,</span> <span class="n">xsecs_benchmarks</span><span class="p">,</span> <span class="n">xsec_errors_benchmarks</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">cross_sections</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">benchmarks</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">benchmarks</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="p">)</span>

<span class="n">thetas_morphing</span><span class="p">,</span> <span class="n">xsecs_morphing</span><span class="p">,</span> <span class="n">xsec_errors_morphing</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">cross_sections</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="n">sampling</span><span class="o">.</span><span class="n">random_morphing_points</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)])</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>21:02 madminer.sampling    INFO    Starting cross-section calculation
21:02 madminer.sampling    INFO    Starting cross-section calculation
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">2.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xsecs_morphing</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas_morphing</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">thetas_morphing</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">xsecs_morphing</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">40.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas_benchmarks</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">thetas_benchmarks</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">xsecs_benchmarks</span><span class="p">,</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">200.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>

<span class="n">cb</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;xsec [pb]&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span><span class="mf">3.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span><span class="mf">3.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/tutorial_particle_physics/3a_likelihood_ratio_18_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What  you see here is a morphing algorithm in action. We only asked MadGraph to calculate event weights (differential cross sections, or basically squared matrix elements) at six fixed parameter points (shown here as squares with black edges). But with our knowledge about the structure of the process we can interpolate any observable to any parameter point without loss (except that statistical uncertainties might increase)!</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Train-likelihood-ratio-estimator">3. Train likelihood ratio estimator<a class="anchor-link" href="#3.-Train-likelihood-ratio-estimator"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's now time to build the neural network that estimates the likelihood ratio. The central object for this is the <code>madminer.ml.ParameterizedRatioEstimator</code> class. It defines functions that train, save, load, and evaluate the estimators.</p>
<p>In the initialization, the keywords <code>n_hidden</code> and <code>activation</code> define the architecture of the (fully connected) neural network:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">ParameterizedRatioEstimator</span><span class="p">(</span>
    <span class="n">n_hidden</span><span class="o">=</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span><span class="mi">60</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To train this model we will minimize the ALICES loss function described in <a href="https://arxiv.org/abs/1808.00973">"Likelihood-free inference with an improved cross-entropy estimator"</a>. Many alternatives, including RASCAL, are described in <a href="https://arxiv.org/abs/1805.00013">"Constraining Effective Field Theories With Machine Learning"</a> and <a href="https://arxiv.org/abs/1805.00020">"A Guide to Constraining Effective Field Theories With Machine Learning"</a>. There is also SCANDAL introduced in <a href="https://arxiv.org/abs/1805.12244">"Mining gold from implicit models to improve likelihood-free inference"</a>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;alices&#39;</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta0_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;data/samples/y_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">r_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/r_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">t_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/t_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scale_parameters</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">estimator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;models/alices&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>21:38 madminer.ml          INFO    Starting training
21:38 madminer.ml          INFO      Method:                 alices
21:38 madminer.ml          INFO      alpha:                  10
21:38 madminer.ml          INFO      Batch size:             128
21:38 madminer.ml          INFO      Optimizer:              amsgrad
21:38 madminer.ml          INFO      Epochs:                 10
21:38 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001
21:38 madminer.ml          INFO      Validation split:       0.25
21:38 madminer.ml          INFO      Early stopping:         True
21:38 madminer.ml          INFO      Scale inputs:           True
21:38 madminer.ml          INFO      Scale parameters:       True
21:38 madminer.ml          INFO      Shuffle labels          False
21:38 madminer.ml          INFO      Samples:                all
21:38 madminer.ml          INFO    Loading training data
21:38 madminer.utils.vario INFO      Loading data/samples/theta0_train_ratio.npy into RAM
21:38 madminer.utils.vario INFO      Loading data/samples/x_train_ratio.npy into RAM
21:38 madminer.utils.vario INFO      Loading data/samples/y_train_ratio.npy into RAM
21:38 madminer.utils.vario INFO      Loading data/samples/r_xz_train_ratio.npy into RAM
21:38 madminer.utils.vario INFO      Loading data/samples/t_xz_train_ratio.npy into RAM
21:38 madminer.ml          INFO    Found 500000 samples with 2 parameters and 3 observables
21:38 madminer.ml          INFO    Setting up input rescaling
21:38 madminer.ml          INFO    Rescaling parameters
21:38 madminer.ml          INFO    Setting up parameter rescaling
21:38 madminer.ml          INFO    Creating model
21:38 madminer.ml          INFO    Training model
21:38 madminer.utils.ml.tr INFO    Training on CPU with single precision
21:39 madminer.utils.ml.tr INFO      Epoch   1: train loss  1.03808 (improved_xe:  0.681, mse_score:  0.036)
21:39 madminer.utils.ml.tr INFO                 val. loss   0.97908 (improved_xe:  0.679, mse_score:  0.030)
21:39 madminer.utils.ml.tr INFO      Epoch   2: train loss  0.96923 (improved_xe:  0.677, mse_score:  0.029)
21:39 madminer.utils.ml.tr INFO                 val. loss   0.95581 (improved_xe:  0.677, mse_score:  0.028)
21:39 madminer.utils.ml.tr INFO      Epoch   3: train loss  0.95418 (improved_xe:  0.677, mse_score:  0.028)
21:39 madminer.utils.ml.tr INFO                 val. loss   0.94684 (improved_xe:  0.677, mse_score:  0.027)
21:40 madminer.utils.ml.tr INFO      Epoch   4: train loss  0.94868 (improved_xe:  0.677, mse_score:  0.027)
21:40 madminer.utils.ml.tr INFO                 val. loss   0.94268 (improved_xe:  0.677, mse_score:  0.027)
21:40 madminer.utils.ml.tr INFO      Epoch   5: train loss  0.94466 (improved_xe:  0.677, mse_score:  0.027)
21:40 madminer.utils.ml.tr INFO                 val. loss   0.95316 (improved_xe:  0.677, mse_score:  0.028)
21:41 madminer.utils.ml.tr INFO      Epoch   6: train loss  0.94237 (improved_xe:  0.677, mse_score:  0.027)
21:41 madminer.utils.ml.tr INFO                 val. loss   0.94076 (improved_xe:  0.677, mse_score:  0.026)
21:41 madminer.utils.ml.tr INFO      Epoch   7: train loss  0.93981 (improved_xe:  0.677, mse_score:  0.026)
21:41 madminer.utils.ml.tr INFO                 val. loss   0.93925 (improved_xe:  0.677, mse_score:  0.026)
21:41 madminer.utils.ml.tr INFO      Epoch   8: train loss  0.93829 (improved_xe:  0.677, mse_score:  0.026)
21:41 madminer.utils.ml.tr INFO                 val. loss   0.93697 (improved_xe:  0.677, mse_score:  0.026)
21:42 madminer.utils.ml.tr INFO      Epoch   9: train loss  0.93718 (improved_xe:  0.677, mse_score:  0.026)
21:42 madminer.utils.ml.tr INFO                 val. loss   0.93703 (improved_xe:  0.677, mse_score:  0.026)
21:42 madminer.utils.ml.tr INFO      Epoch  10: train loss  0.93598 (improved_xe:  0.677, mse_score:  0.026)
21:42 madminer.utils.ml.tr INFO                 val. loss   0.93583 (improved_xe:  0.677, mse_score:  0.026)
21:42 madminer.utils.ml.tr INFO    Early stopping did not improve performance
21:42 madminer.utils.ml.tr INFO    Training time spend on:
21:42 madminer.utils.ml.tr INFO                      initialize model:   0.00h
21:42 madminer.utils.ml.tr INFO                                   ALL:   0.07h
21:42 madminer.utils.ml.tr INFO                            check data:   0.00h
21:42 madminer.utils.ml.tr INFO                          make dataset:   0.00h
21:42 madminer.utils.ml.tr INFO                       make dataloader:   0.00h
21:42 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h
21:42 madminer.utils.ml.tr INFO                   initialize training:   0.00h
21:42 madminer.utils.ml.tr INFO                                set lr:   0.00h
21:42 madminer.utils.ml.tr INFO                   load training batch:   0.02h
21:42 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h
21:42 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.01h
21:42 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.01h
21:42 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.01h
21:42 madminer.utils.ml.tr INFO                 training forward pass:   0.02h
21:42 madminer.utils.ml.tr INFO                   training sum losses:   0.00h
21:42 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h
21:42 madminer.utils.ml.tr INFO                         opt: backward:   0.01h
21:42 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h
21:42 madminer.utils.ml.tr INFO                             opt: step:   0.00h
21:42 madminer.utils.ml.tr INFO                        optimizer step:   0.01h
21:42 madminer.utils.ml.tr INFO                 load validation batch:   0.01h
21:42 madminer.utils.ml.tr INFO               validation forward pass:   0.01h
21:42 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h
21:42 madminer.utils.ml.tr INFO                        early stopping:   0.00h
21:42 madminer.utils.ml.tr INFO                          report epoch:   0.00h
21:42 madminer.ml          INFO    Saving model to models/alices
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's for fun also train a model that only used <code>pt_j1</code> as input observable, which can be specified using the option <code>features</code> when defining the <code>ParameterizedRatioEstimator</code></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">estimator_pt</span> <span class="o">=</span> <span class="n">ParameterizedRatioEstimator</span><span class="p">(</span>
    <span class="n">n_hidden</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span><span class="mi">40</span><span class="p">),</span>
    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
    <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">estimator_pt</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;alices&#39;</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta0_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;data/samples/y_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">r_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/r_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">t_xz</span><span class="o">=</span><span class="s1">&#39;data/samples/t_xz_train_ratio.npy&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scale_parameters</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">estimator_pt</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;models/alices_pt&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>22:56 madminer.ml          INFO    Starting training
22:56 madminer.ml          INFO      Method:                 alices
22:56 madminer.ml          INFO      alpha:                  8
22:56 madminer.ml          INFO      Batch size:             128
22:56 madminer.ml          INFO      Optimizer:              amsgrad
22:56 madminer.ml          INFO      Epochs:                 10
22:56 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001
22:56 madminer.ml          INFO      Validation split:       0.25
22:56 madminer.ml          INFO      Early stopping:         True
22:56 madminer.ml          INFO      Scale inputs:           True
22:56 madminer.ml          INFO      Scale parameters:       True
22:56 madminer.ml          INFO      Shuffle labels          False
22:56 madminer.ml          INFO      Samples:                all
22:56 madminer.ml          INFO    Loading training data
22:56 madminer.utils.vario INFO      Loading data/samples/theta0_train_ratio.npy into RAM
22:56 madminer.utils.vario INFO      Loading data/samples/x_train_ratio.npy into RAM
22:56 madminer.utils.vario INFO      Loading data/samples/y_train_ratio.npy into RAM
22:56 madminer.utils.vario INFO      Loading data/samples/r_xz_train_ratio.npy into RAM
22:56 madminer.utils.vario INFO      Loading data/samples/t_xz_train_ratio.npy into RAM
22:56 madminer.ml          INFO    Found 500000 samples with 2 parameters and 3 observables
22:56 madminer.ml          INFO    Setting up input rescaling
22:56 madminer.ml          INFO    Rescaling parameters
22:56 madminer.ml          INFO    Setting up parameter rescaling
22:56 madminer.ml          INFO    Only using 1 of 3 observables
22:56 madminer.ml          INFO    Creating model
22:56 madminer.ml          INFO    Training model
22:56 madminer.utils.ml.tr INFO    Training on CPU with single precision
22:56 madminer.utils.ml.tr INFO      Epoch   1: train loss  1.06877 (improved_xe:  0.686, mse_score:  0.048)
22:56 madminer.utils.ml.tr INFO                 val. loss   1.09418 (improved_xe:  0.684, mse_score:  0.051)
22:56 madminer.utils.ml.tr INFO      Epoch   2: train loss  1.04290 (improved_xe:  0.684, mse_score:  0.045)
22:56 madminer.utils.ml.tr INFO                 val. loss   1.08987 (improved_xe:  0.684, mse_score:  0.051)
22:57 madminer.utils.ml.tr INFO      Epoch   3: train loss  1.03923 (improved_xe:  0.684, mse_score:  0.044)
22:57 madminer.utils.ml.tr INFO                 val. loss   1.09190 (improved_xe:  0.684, mse_score:  0.051)
22:57 madminer.utils.ml.tr INFO      Epoch   4: train loss  1.03722 (improved_xe:  0.684, mse_score:  0.044)
22:57 madminer.utils.ml.tr INFO                 val. loss   1.08761 (improved_xe:  0.684, mse_score:  0.050)
22:57 madminer.utils.ml.tr INFO      Epoch   5: train loss  1.03596 (improved_xe:  0.684, mse_score:  0.044)
22:57 madminer.utils.ml.tr INFO                 val. loss   1.08598 (improved_xe:  0.684, mse_score:  0.050)
22:58 madminer.utils.ml.tr INFO      Epoch   6: train loss  1.03505 (improved_xe:  0.684, mse_score:  0.044)
22:58 madminer.utils.ml.tr INFO                 val. loss   1.08765 (improved_xe:  0.684, mse_score:  0.050)
22:58 madminer.utils.ml.tr INFO      Epoch   7: train loss  1.03448 (improved_xe:  0.684, mse_score:  0.044)
22:58 madminer.utils.ml.tr INFO                 val. loss   1.08483 (improved_xe:  0.684, mse_score:  0.050)
22:58 madminer.utils.ml.tr INFO      Epoch   8: train loss  1.03407 (improved_xe:  0.684, mse_score:  0.044)
22:58 madminer.utils.ml.tr INFO                 val. loss   1.08467 (improved_xe:  0.684, mse_score:  0.050)
22:59 madminer.utils.ml.tr INFO      Epoch   9: train loss  1.03343 (improved_xe:  0.684, mse_score:  0.044)
22:59 madminer.utils.ml.tr INFO                 val. loss   1.08395 (improved_xe:  0.684, mse_score:  0.050)
22:59 madminer.utils.ml.tr INFO      Epoch  10: train loss  1.03330 (improved_xe:  0.684, mse_score:  0.044)
22:59 madminer.utils.ml.tr INFO                 val. loss   1.08393 (improved_xe:  0.684, mse_score:  0.050)
22:59 madminer.utils.ml.tr INFO    Early stopping did not improve performance
22:59 madminer.utils.ml.tr INFO    Training time spend on:
22:59 madminer.utils.ml.tr INFO                      initialize model:   0.00h
22:59 madminer.utils.ml.tr INFO                                   ALL:   0.05h
22:59 madminer.utils.ml.tr INFO                            check data:   0.00h
22:59 madminer.utils.ml.tr INFO                          make dataset:   0.00h
22:59 madminer.utils.ml.tr INFO                       make dataloader:   0.00h
22:59 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h
22:59 madminer.utils.ml.tr INFO                   initialize training:   0.00h
22:59 madminer.utils.ml.tr INFO                                set lr:   0.00h
22:59 madminer.utils.ml.tr INFO                   load training batch:   0.02h
22:59 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h
22:59 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.01h
22:59 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.01h
22:59 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.00h
22:59 madminer.utils.ml.tr INFO                 training forward pass:   0.02h
22:59 madminer.utils.ml.tr INFO                   training sum losses:   0.00h
22:59 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h
22:59 madminer.utils.ml.tr INFO                         opt: backward:   0.01h
22:59 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h
22:59 madminer.utils.ml.tr INFO                             opt: step:   0.00h
22:59 madminer.utils.ml.tr INFO                        optimizer step:   0.01h
22:59 madminer.utils.ml.tr INFO                 load validation batch:   0.01h
22:59 madminer.utils.ml.tr INFO               validation forward pass:   0.01h
22:59 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h
22:59 madminer.utils.ml.tr INFO                        early stopping:   0.00h
22:59 madminer.utils.ml.tr INFO                          report epoch:   0.00h
22:59 madminer.ml          INFO    Saving model to models/alices_pt
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Evaluate-likelihood-ratio-estimator">4. Evaluate likelihood ratio estimator<a class="anchor-link" href="#4.-Evaluate-likelihood-ratio-estimator"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>estimator.evaluate_log_likelihood_ratio(theta,x)</code> estimated the log likelihood ratio and the score for all combination between the given phase-space points <code>x</code> and parameters <code>theta</code>. That is, if given 100 events <code>x</code> and a grid of 25 <code>theta</code> points, it will return 25*100 estimates for the log likelihood ratio and 25*100 estimates for the score, both indexed by <code>[i_theta,i_x]</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">theta_each</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span>
<span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">theta_each</span><span class="p">,</span> <span class="n">theta_each</span><span class="p">)</span>
<span class="n">theta_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">theta0</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">theta1</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span><span class="o">.</span><span class="n">T</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/samples/theta_grid.npy&#39;</span><span class="p">,</span> <span class="n">theta_grid</span><span class="p">)</span>

<span class="n">theta_denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]])</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/samples/theta_ref.npy&#39;</span><span class="p">,</span> <span class="n">theta_denom</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;models/alices&#39;</span><span class="p">)</span>

<span class="n">log_r_hat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">evaluate_log_likelihood_ratio</span><span class="p">(</span>
    <span class="n">theta</span><span class="o">=</span><span class="s1">&#39;data/samples/theta_grid.npy&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;data/samples/x_test.npy&#39;</span><span class="p">,</span>
    <span class="n">evaluate_score</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>13:08 madminer.ml          INFO    Loading model from models/alices
13:08 madminer.ml          INFO    Loading evaluation data
13:08 madminer.utils.vario INFO      Loading data/samples/x_test.npy into RAM
13:08 madminer.utils.vario INFO      Loading data/samples/theta_grid.npy into RAM
13:08 madminer.ml          INFO    Starting ratio evaluation for 625000 x-theta combinations
13:08 madminer.ml          INFO    Evaluation done
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the result:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">bin_size</span> <span class="o">=</span> <span class="n">theta_each</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">theta_each</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">theta_each</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">bin_size</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">theta_each</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">bin_size</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_each</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">expected_llr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_r_hat</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">best_fit</span> <span class="o">=</span> <span class="n">theta_grid</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="o">-</span><span class="mf">2.</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">)]</span>

<span class="n">cmin</span><span class="p">,</span> <span class="n">cmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">expected_llr</span><span class="p">)</span>
    
<span class="n">pcm</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">expected_llr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">)),</span>
                    <span class="n">norm</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">),</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis_r&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pcm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">extend</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">best_fit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">best_fit</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mf">80.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta_0$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta_1$&#39;</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbb{E}_x [ -2\, \log \,\hat{r}(x | \theta, \theta_{SM}) ]$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/tutorial_particle_physics/3a_likelihood_ratio_32_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that in this tutorial our sample size was very small, and the network might not really have a chance to converge to the correct likelihood ratio function. So don't worry if you find a minimum that is not at the right point (the SM, i.e. the origin in this plot). Feel free to dial up the event numbers in the run card as well as the training samples and see what happens then!</p>

</div>
</div>
</div>
</div>

 


    </main>
    
            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  
    
    

    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/madminer-tutorial/choose_surrogate.html">
       <span class="u-margin-right-tiny"></span> Train model
    </a>
  

  
    

    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/madminer-tutorial/tutorial_particle_physics/3b_score.html">
      Score <span class="u-margin-right-tiny"></span> 
    </a>
  
</nav>

              <footer>
  <p class="footer">This page was created by <a href="https://github.com/diana-hep/madminer">The MadMiner Team</a>. The source is <a href="https://github.com/cranmer/madminer-tutorial">here</a>.</p>
</footer>

            </div>

        </div>
      </main>
    </div>
  </body>
</html>
